#!/usr/bin/env python3
"""
ì„±ëŠ¥ ê°œì„ ëœ YouTube í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
- í¬ë¡¤ë§ ì•ˆì •ì„± í…ŒìŠ¤íŠ¸
- ëŒ“ê¸€ ì¶”ì¶œ ì†ë„ í…ŒìŠ¤íŠ¸
- í‚¤ì›Œë“œ ë¶„ì„ í…ŒìŠ¤íŠ¸
- ë°œí–‰ì¼ íŒŒì‹± í…ŒìŠ¤íŠ¸
- ì—‘ì…€ ì €ì¥ í…ŒìŠ¤íŠ¸
"""

import asyncio
import time
from datetime import datetime, timedelta
from youtube_crawler import YouTubeCrawler, ConfigManager, PerformanceMonitor, KeywordAnalyzer

def test_crawler_stability():
    """í¬ë¡¤ëŸ¬ ì•ˆì •ì„± í…ŒìŠ¤íŠ¸"""
    print("ğŸ”§ í¬ë¡¤ëŸ¬ ì•ˆì •ì„± í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    config = ConfigManager()
    config.update({
        'max_workers': 4,
        'timeout': 30,
        'retry_count': 3,
        'headless': True,
        'scroll_count': 2,
        'wait_time': 1.0
    })
    
    crawler = YouTubeCrawler(config)
    
    try:
        # ê°„ë‹¨í•œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
        keywords = ["íŒŒì´ì¬ íŠœí† ë¦¬ì–¼"]
        videos = crawler.search_videos(keywords, max_videos_per_keyword=3)
        
        print(f"âœ… ê²€ìƒ‰ ì„±ê³µ: {len(videos)}ê°œ ì˜ìƒ ë°œê²¬")
        
        if videos:
            # ì²« ë²ˆì§¸ ì˜ìƒì˜ ëŒ“ê¸€ í…ŒìŠ¤íŠ¸
            video_id = videos[0].get('video_id')
            if video_id:
                comments = crawler.get_video_comments(video_id, max_comments=5)
                print(f"âœ… ëŒ“ê¸€ ìˆ˜ì§‘ ì„±ê³µ: {len(comments)}ê°œ ëŒ“ê¸€")
        
        # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¶œë ¥
        metrics = crawler.get_performance_metrics()
        print(f"ğŸ“Š ì„±ëŠ¥ ë©”íŠ¸ë¦­: {metrics}")
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
    finally:
        crawler.close()

def test_comment_extraction_speed():
    """ëŒ“ê¸€ ì¶”ì¶œ ì†ë„ í…ŒìŠ¤íŠ¸"""
    print("\nâš¡ ëŒ“ê¸€ ì¶”ì¶œ ì†ë„ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    config = ConfigManager()
    config.update({
        'max_workers': 6,
        'comment_batch_size': 10,
        'max_comments_per_video': 20
    })
    
    crawler = YouTubeCrawler(config)
    
    try:
        # ì¸ê¸° ì˜ìƒ ê²€ìƒ‰
        keywords = ["ì½”ë”©"]
        videos = crawler.search_videos(keywords, max_videos_per_keyword=2)
        
        if videos:
            start_time = time.time()
            
            # ëŒ“ê¸€ ìˆ˜ì§‘
            all_comments = []
            for video in videos:
                video_id = video.get('video_id')
                if video_id:
                    comments = crawler.get_video_comments(video_id, max_comments=10)
                    all_comments.extend(comments)
            
            end_time = time.time()
            elapsed = end_time - start_time
            
            print(f"âœ… ëŒ“ê¸€ ìˆ˜ì§‘ ì™„ë£Œ: {len(all_comments)}ê°œ ëŒ“ê¸€")
            print(f"â±ï¸ ì†Œìš” ì‹œê°„: {elapsed:.2f}ì´ˆ")
            print(f"ğŸš€ í‰ê·  ì†ë„: {len(all_comments)/elapsed:.1f} ëŒ“ê¸€/ì´ˆ")
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
    finally:
        crawler.close()

def test_keyword_analysis():
    """í‚¤ì›Œë“œ ë¶„ì„ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ” í‚¤ì›Œë“œ ë¶„ì„ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    try:
        analyzer = KeywordAnalyzer()
        
        # í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸
        test_texts = [
            "íŒŒì´ì¬ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ëŠ” ì •ë§ ì¢‹ìŠµë‹ˆë‹¤",
            "ì½”ë”©ì„ ë°°ìš°ëŠ” ê²ƒì´ ì¬ë¯¸ìˆì–´ìš”",
            "í”„ë¡œê·¸ë˜ë° ê¸°ì´ˆë¥¼ ê³µë¶€í•˜ê³  ìˆìŠµë‹ˆë‹¤",
            "íŒŒì´ì¬ìœ¼ë¡œ ì›¹ ê°œë°œì„ í•˜ê³  ìˆì–´ìš”",
            "ì½”ë”© ì‹¤ë ¥ì„ í–¥ìƒì‹œí‚¤ê³  ì‹¶ìŠµë‹ˆë‹¤"
        ]
        
        # í‚¤ì›Œë“œ ë¶„ì„ ì‹¤í–‰
        start_time = time.time()
        analysis = analyzer.analyze_keywords(test_texts, top_n=10)
        end_time = time.time()
        
        print(f"âœ… í‚¤ì›Œë“œ ë¶„ì„ ì™„ë£Œ: {end_time - start_time:.3f}ì´ˆ")
        print(f"ğŸ“Š ë¶„ì„ ê²°ê³¼:")
        print(f"  - ìƒìœ„ í‚¤ì›Œë“œ: {analysis.get('top_keywords', {})}")
        print(f"  - ì´ ë‹¨ì–´ ìˆ˜: {analysis.get('total_words', 0)}")
        print(f"  - ê³ ìœ  ë‹¨ì–´ ìˆ˜: {analysis.get('unique_words', 0)}")
        print(f"  - ê°ì • ì ìˆ˜: {analysis.get('sentiment_score', 0):.3f}")
        print(f"  - ê°ì • ë¼ë²¨: {analysis.get('sentiment_label', 'N/A')}")
        
    except Exception as e:
        print(f"âŒ í‚¤ì›Œë“œ ë¶„ì„ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

def test_upload_time_parsing():
    """ë°œí–‰ì¼ íŒŒì‹± í…ŒìŠ¤íŠ¸"""
    print("\nğŸ“… ë°œí–‰ì¼ íŒŒì‹± í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    crawler = YouTubeCrawler()
    
    # ë‹¤ì–‘í•œ ì‹œê°„ í˜•ì‹ í…ŒìŠ¤íŠ¸
    test_times = [
        "3ì¼ ì „",
        "1ì£¼ ì „", 
        "2ê°œì›” ì „",
        "1ë…„ ì „",
        "2024. 1. 15.",
        "2024ë…„ 1ì›” 15ì¼",
        "2024-01-15",
        "ë°©ê¸ˆ ì „",
        "5ì‹œê°„ ì „",
        "30ë¶„ ì „"
    ]
    
    for time_text in test_times:
        try:
            parsed_time = crawler._parse_upload_time(time_text)
            if parsed_time:
                formatted = parsed_time.strftime('%Y-%m-%d %H:%M:%S')
                print(f"âœ… '{time_text}' â†’ {formatted}")
            else:
                print(f"âš ï¸ '{time_text}' â†’ íŒŒì‹± ì‹¤íŒ¨")
        except Exception as e:
            print(f"âŒ '{time_text}' â†’ ì˜¤ë¥˜: {e}")
    
    crawler.close()

def test_excel_saving():
    """ì—‘ì…€ ì €ì¥ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ’¾ ì—‘ì…€ ì €ì¥ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    config = ConfigManager()
    config.update({
        'excel_encoding': 'utf-8-sig',
        'enable_keyword_analysis': True
    })
    
    crawler = YouTubeCrawler(config)
    
    try:
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
        test_videos = [
            {
                'keyword': 'í…ŒìŠ¤íŠ¸',
                'title': 'í…ŒìŠ¤íŠ¸ ì˜ìƒ 1',
                'channel_name': 'í…ŒìŠ¤íŠ¸ ì±„ë„',
                'view_count': '1,000íšŒ',
                'upload_time': '3ì¼ ì „',
                'video_id': 'test123',
                'video_url': 'https://youtube.com/watch?v=test123'
            },
            {
                'keyword': 'í…ŒìŠ¤íŠ¸',
                'title': 'í…ŒìŠ¤íŠ¸ ì˜ìƒ 2', 
                'channel_name': 'í…ŒìŠ¤íŠ¸ ì±„ë„',
                'view_count': '2,000íšŒ',
                'upload_time': '1ì£¼ ì „',
                'video_id': 'test456',
                'video_url': 'https://youtube.com/watch?v=test456'
            }
        ]
        
        test_comments = [
            {
                'video_id': 'test123',
                'comment_text': 'ì •ë§ ì¢‹ì€ ì˜ìƒì´ë„¤ìš”!',
                'author': 'ì‚¬ìš©ì1',
                'like_count': 10,
                'comment_time': '2ì¼ ì „'
            },
            {
                'video_id': 'test123',
                'comment_text': 'ë„ì›€ì´ ë§ì´ ë˜ì—ˆìŠµë‹ˆë‹¤',
                'author': 'ì‚¬ìš©ì2', 
                'like_count': 5,
                'comment_time': '1ì¼ ì „'
            }
        ]
        
        # ì—‘ì…€ ì €ì¥ í…ŒìŠ¤íŠ¸
        filename = "test_output.xlsx"
        start_time = time.time()
        
        saved_file = crawler.save_to_excel(test_videos, test_comments, filename)
        
        end_time = time.time()
        
        if saved_file:
            print(f"âœ… ì—‘ì…€ ì €ì¥ ì„±ê³µ: {saved_file}")
            print(f"â±ï¸ ì €ì¥ ì‹œê°„: {end_time - start_time:.3f}ì´ˆ")
        else:
            print("âŒ ì—‘ì…€ ì €ì¥ ì‹¤íŒ¨")
            
    except Exception as e:
        print(f"âŒ ì—‘ì…€ ì €ì¥ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
    finally:
        crawler.close()

async def test_async_performance():
    """ë¹„ë™ê¸° ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print("\nğŸš€ ë¹„ë™ê¸° ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    config = ConfigManager()
    config.update({
        'max_workers': 6,
        'max_comments_per_video': 10
    })
    
    crawler = YouTubeCrawler(config)
    
    try:
        # ë¹„ë™ê¸° ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
        keywords = ["íŒŒì´ì¬", "ì½”ë”©"]
        start_time = time.time()
        
        videos = await crawler.search_videos_async(keywords, max_videos_per_keyword=2)
        
        if videos:
            # ë¹„ë™ê¸° ëŒ“ê¸€ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸
            comments = await crawler.get_comments_for_videos_async(videos, max_comments_per_video=5)
            
            end_time = time.time()
            elapsed = end_time - start_time
            
            print(f"âœ… ë¹„ë™ê¸° ì²˜ë¦¬ ì™„ë£Œ:")
            print(f"  - ì˜ìƒ ìˆ˜: {len(videos)}")
            print(f"  - ëŒ“ê¸€ ìˆ˜: {len(comments)}")
            print(f"  - ì†Œìš” ì‹œê°„: {elapsed:.2f}ì´ˆ")
            
    except Exception as e:
        print(f"âŒ ë¹„ë™ê¸° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
    finally:
        crawler.close()

def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    print("ğŸ¯ YouTube í¬ë¡¤ëŸ¬ ì„±ëŠ¥ ê°œì„  í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 50)
    
    # 1. í¬ë¡¤ëŸ¬ ì•ˆì •ì„± í…ŒìŠ¤íŠ¸
    test_crawler_stability()
    
    # 2. ëŒ“ê¸€ ì¶”ì¶œ ì†ë„ í…ŒìŠ¤íŠ¸
    test_comment_extraction_speed()
    
    # 3. í‚¤ì›Œë“œ ë¶„ì„ í…ŒìŠ¤íŠ¸
    test_keyword_analysis()
    
    # 4. ë°œí–‰ì¼ íŒŒì‹± í…ŒìŠ¤íŠ¸
    test_upload_time_parsing()
    
    # 5. ì—‘ì…€ ì €ì¥ í…ŒìŠ¤íŠ¸
    test_excel_saving()
    
    # 6. ë¹„ë™ê¸° ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
    asyncio.run(test_async_performance())
    
    print("\n" + "=" * 50)
    print("ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

if __name__ == "__main__":
    main()
